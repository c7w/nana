"""
è®ºæ–‡æœåŠ¡å±‚ - å¤ç”¨ç°æœ‰çš„è®ºæ–‡å¤„ç†é€»è¾‘
"""

import json
import pandas as pd
from pathlib import Path
from datetime import datetime, timezone
from typing import List, Dict, Optional
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).resolve().parent.parent.parent.parent
sys.path.append(str(project_root))

from api.models import PaperSummary, PaperDetail, PapersListResponse

class PaperService:
    def __init__(self):
        self.project_root = project_root
        self.agent_storage_path = self.project_root / 'storage' / 'paper_search_agent'
        self.cache_path = self.agent_storage_path / 'cache.json'

    def format_collection_time(self, collected_at_str: str) -> str:
        """æ ¼å¼åŒ–æ”¶é›†æ—¶é—´"""
        try:
            dt = datetime.fromisoformat(collected_at_str.replace('Z', '+00:00'))
            dt_local = dt.astimezone()
            return dt_local.strftime("%m/%d %H:%M")
        except Exception:
            return "Unknown"

    def load_cache(self) -> Dict:
        """åŠ è½½ç¼“å­˜æ–‡ä»¶"""
        if self.cache_path.exists():
            with open(self.cache_path, 'r') as f:
                return json.load(f)
        return {}

    def load_papers_data(self) -> PapersListResponse:
        """åŠ è½½è®ºæ–‡æ•°æ®ï¼Œè¿”å›æ ¼å¼åŒ–çš„åˆ—è¡¨"""
        cache = self.load_cache()
        papers = []
        
        for key, paper in cache.items():
            # åªæ˜¾ç¤ºæœ‰æ‘˜è¦çš„è®ºæ–‡
            if not paper.get('summary_path'):
                continue
                
            collected_at = paper.get('collected_at', '')
            formatted_time = self.format_collection_time(collected_at)
            
            display_title = f"[{paper.get('arxiv_id', 'N/A')}] {paper.get('title', 'No Title')} | ğŸ“… {formatted_time}"
            
            paper_summary = PaperSummary(
                arxiv_id=paper.get('arxiv_id'),
                title=paper.get('title', 'No Title'),
                display_title=display_title,
                pdf_url=paper.get('pdf_url'),
                summary_path=paper.get('summary_path'),
                collected_at=collected_at
            )
            papers.append(paper_summary)

        # æŒ‰æ”¶é›†æ—¶é—´æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
        papers.sort(key=lambda x: x.collected_at, reverse=True)
        
        return PapersListResponse(papers=papers, total=len(papers))

    def get_paper_by_display_title(self, display_title: str) -> Optional[PaperDetail]:
        """æ ¹æ®æ˜¾ç¤ºæ ‡é¢˜è·å–è®ºæ–‡è¯¦æƒ…"""
        cache = self.load_cache()
        
        # æ‰¾åˆ°åŒ¹é…çš„è®ºæ–‡
        for paper in cache.values():
            collected_at = paper.get('collected_at', '')
            formatted_time = self.format_collection_time(collected_at)
            paper_display_title = f"[{paper.get('arxiv_id', 'N/A')}] {paper.get('title', 'No Title')} | ğŸ“… {formatted_time}"
            
            if paper_display_title == display_title:
                # è¯»å–æ‘˜è¦å†…å®¹
                summary_content = "### No summary available for this paper."
                summary_path_str = paper.get('summary_path')
                if summary_path_str:
                    summary_path = self.project_root / summary_path_str
                    if summary_path.exists():
                        summary_content = summary_path.read_text()
                    else:
                        summary_content = f"### Summary file not found at:\n`{summary_path_str}`"
                
                return PaperDetail(
                    arxiv_id=paper.get('arxiv_id'),
                    title=paper.get('title', 'No Title'),
                    display_title=paper_display_title,
                    pdf_url=paper.get('pdf_url'),
                    summary=summary_content,
                    collected_at=collected_at
                )
        
        return None

    def get_paper_by_arxiv_id(self, arxiv_id: str) -> Optional[PaperDetail]:
        """æ ¹æ®arXiv IDè·å–è®ºæ–‡è¯¦æƒ…"""
        cache = self.load_cache()
        
        for paper in cache.values():
            if paper.get('arxiv_id') == arxiv_id:
                # è¯»å–æ‘˜è¦å†…å®¹
                summary_content = "### No summary available for this paper."
                summary_path_str = paper.get('summary_path')
                if summary_path_str:
                    summary_path = self.project_root / summary_path_str
                    if summary_path.exists():
                        summary_content = summary_path.read_text()
                    else:
                        summary_content = f"### Summary file not found at:\n`{summary_path_str}`"
                
                # ç”Ÿæˆdisplay_title
                collected_at = paper.get('collected_at', '')
                formatted_time = self.format_collection_time(collected_at)
                display_title = f"[{paper.get('arxiv_id', 'N/A')}] {paper.get('title', 'No Title')} | ğŸ“… {formatted_time}"
                
                return PaperDetail(
                    arxiv_id=paper.get('arxiv_id'),
                    title=paper.get('title', 'No Title'),
                    display_title=display_title,
                    pdf_url=paper.get('pdf_url'),
                    summary=summary_content,
                    collected_at=paper.get('collected_at', '')
                )
        
        return None

    def get_paper_by_id(self, paper_id: str) -> Optional[PaperDetail]:
        """
        æ ¹æ®paper_idè·å–è®ºæ–‡è¯¦æƒ…ï¼ˆå…ˆå°è¯•arxiv_idï¼Œå†å°è¯•titleï¼‰
        """
        # é¦–å…ˆå°è¯•ä½¿ç”¨arxiv_idæŸ¥æ‰¾
        paper = self.get_paper_by_arxiv_id(paper_id)
        if paper:
            return paper
        
        # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•ä½¿ç”¨titleæŸ¥æ‰¾
        cache = self.load_cache()
        for cached_paper in cache.values():
            if cached_paper.get('title') == paper_id:
                # è¯»å–æ‘˜è¦å†…å®¹
                summary_content = "### No summary available for this paper."
                summary_path_str = cached_paper.get('summary_path')
                if summary_path_str:
                    summary_path = self.project_root / summary_path_str
                    if summary_path.exists():
                        summary_content = summary_path.read_text()
                    else:
                        summary_content = f"### Summary file not found at:\n`{summary_path_str}`"
                
                # ç”Ÿæˆdisplay_title
                collected_at = cached_paper.get('collected_at', '')
                formatted_time = self.format_collection_time(collected_at)
                display_title = f"[{cached_paper.get('arxiv_id', 'N/A')}] {cached_paper.get('title', 'No Title')} | ğŸ“… {formatted_time}"
                
                return PaperDetail(
                    arxiv_id=cached_paper.get('arxiv_id'),
                    title=cached_paper.get('title', 'No Title'),
                    display_title=display_title,
                    pdf_url=cached_paper.get('pdf_url'),
                    summary=summary_content,
                    collected_at=cached_paper.get('collected_at', '')
                )
        
        return None

    def search_papers(self, keyword: str) -> PapersListResponse:
        """æœç´¢è®ºæ–‡"""
        all_papers = self.load_papers_data()
        
        if not keyword:
            return all_papers
        
        # è¿‡æ»¤åŒ¹é…å…³é”®è¯çš„è®ºæ–‡
        filtered_papers = [
            paper for paper in all_papers.papers 
            if keyword.lower() in paper.display_title.lower()
        ]
        
        return PapersListResponse(papers=filtered_papers, total=len(filtered_papers)) 